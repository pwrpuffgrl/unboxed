# Unboxed ğŸ§ ğŸ“¦

_Unbox your documents. Talk to your knowledge._

**Unboxed** is an open-source AI app that uses **Retrieval-Augmented Generation (RAG)** to turn unstructured documents into a smart, conversational assistant.

Ask questions in natural language, get accurate answers grounded in your actual data â€“ PDFs, Markdown, Confluence pages, whatever you've got.

---

## ğŸ” Key Features

- âš™ï¸ Embedding-based document search (OpenAI or open-source models)
- ğŸ§  Context-aware Q&A with GPT (RAG-style prompts)
- ğŸ“¦ Vector store with PostgreSQL + `pgvector`
- ğŸ§© Modular Python backend (FastAPI)
- ğŸŒ Optional UI or API-first usage
- ğŸ§ª Prompt evaluation (Langfuse/promptfoo ready)
- ğŸ”’ **Privacy Protection**: Advanced spaCy-based anonymization system
- ğŸ›¡ï¸ **Two-Way Anonymization**: Questions and answers are anonymized/deanonymized
- ğŸ“‹ **File-Specific Privacy**: Choose privacy mode per document during upload
- ğŸ” **Debug Mode**: Toggle to see anonymized AI responses for transparency

---

## ğŸ“‚ Use cases

- Internal knowledge base search
- Developer docs Q&A
- AI-powered help desk
- Custom ChatGPT for your company

---

> Built for devs who want **control over their LLM stack** â€“ no black boxes, no vendor lock-in.

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- PostgreSQL with pgvector extension
- OpenAI API key
- spaCy with English language model

### Installation

1. **Clone and setup:**

```bash
git clone <your-repo>
cd unboxed
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Install spaCy and language model
python -m spacy download en_core_web_sm
```

2. **Database setup:**

```bash
# Create PostgreSQL database with pgvector
# Run the schema setup
python setup_database.py
```

3. **Environment variables:**

```bash
# Create .env file
DATABASE_URL=postgresql://username:password@localhost:5432/unboxed
OPENAI_API_KEY=your_openai_api_key_here
```

4. **Start the server:**

```bash
cd backend
python3 -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### API Usage

**Upload a document with privacy mode:**

```bash
curl -X POST http://localhost:8000/ingest \
  -F "file=@your_document.pdf" \
  -F "anonymize=true" \
  -F "metadata={\"source\": \"manual\"}"
```

**Ask a question (automatically anonymized):**

```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What did John work on?"}'
```

## ï¿½ï¿½ API Reference

### Endpoints

- `POST /ingest` - Upload and process documents (with privacy mode)
- `POST /ask` - Ask questions using RAG (with anonymization)
- `GET /files` - List all uploaded files
- `DELETE /files/{id}` - Delete file and associated data
- `GET /files/{id}/download` - Download original file
- `GET /health` - Health check
- `GET /stats` - Database statistics
- `GET /docs` - Interactive API documentation

### Supported File Types

- PDF, TXT, Markdown, DOC, DOCX, CSV, JSON

## ï¿½ï¿½ï¸ Architecture

**RAG Pipeline with Privacy:**

1. **Document Ingestion** - Upload â†’ Extract â†’ Chunk â†’ Embed â†’ Store
2. **Privacy Processing** - Anonymize sensitive data â†’ Store mappings
3. **Question Processing** - Question â†’ Anonymize â†’ Embedding â†’ Similarity Search
4. **Answer Generation** - Context + Question â†’ LLM â†’ Deanonymize â†’ Answer

**Tech Stack:**

- **Backend:** FastAPI + PostgreSQL + pgvector
- **AI:** OpenAI GPT-3.5 + text-embedding-ada-002
- **Privacy:** spaCy NER + consistent anonymization
- **File Processing:** PyPDF2, text extraction
- **Vector Search:** pgvector with cosine similarity

## ğŸ”§ Development

### Project Structure

unboxed/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ models/ # Pydantic models
â”‚ â”œâ”€â”€ services/ # Business logic
â”‚ â”œâ”€â”€ config.py # Configuration
â”‚ â”œâ”€â”€ constants.py # Constants
â”‚ â””â”€â”€ main.py # FastAPI app
â”œâ”€â”€ database_schema.sql # Database schema
â”œâ”€â”€ setup_database.py # Database setup
â””â”€â”€ requirements.txt # Dependencies

### Environment Variables

| Variable         | Description                        | Required |
| ---------------- | ---------------------------------- | -------- |
| `DATABASE_URL`   | PostgreSQL connection string       | Yes      |
| `OPENAI_API_KEY` | OpenAI API key                     | Yes      |
| `OPENAI_MODEL`   | LLM model (default: gpt-3.5-turbo) | No       |
| `MAX_CHUNK_SIZE` | Text chunk size (default: 1000)    | No       |

## ğŸ§ª Testing

**Test the API:**

```bash
# Health check
curl http://localhost:8000/health

# Upload test file with privacy mode
curl -X POST http://localhost:8000/ingest \
  -F "file=@test.txt" \
  -F "anonymize=true" \
  -F "metadata={\"test\": true}"

# Ask question (automatically anonymized)
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What did John work on?"}'
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License
